{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# McsPyDataTools Tutorial for data analysis: Spike Detection and Sorting\n",
    "\n",
    "This tutorial gives an introduction into data analysis with the McsPyDataTools toolbox using simple algorithms for spike detection and spike sorting. Its purpose isn't to develop production grade algorithms for spike detection and sorting, but to provide a gentle start into the analysis of neuronal data files with the McsPyDataTools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset we are using in this tutorial stems from a recording with the [MCS Multiwell-MEA system](https://www.multiwell-mea.com) using a 24-well MEA plate. Due to file size constraints, only data from a single well (12 channels) is included in this data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's import the necessary modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# MCS PyData tools\n",
    "import McsPy\n",
    "import McsPy.McsData\n",
    "from McsPy import ureg, Q_\n",
    "\n",
    "# VISUALIZATION TOOLS\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# SUPRESS WARNINGS\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# autoreload modules\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, load the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_folder = r'..\\McsPyDataTools\\McsPy\\tests\\TestData' # adjust this to your local environment\n",
    "file_path = os.path.join(test_data_folder, 'MultiUnitData.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data set contains 3 analog streams and 3 event streams. The following table gives a short overview over the purpose of these streams:\n",
    "\n",
    "| **Stream**       | **Content**                         |\n",
    "|------------------|-------------------------------------|\n",
    "| Analog Stream 0  | Electrode Data                      |\n",
    "| Analog Stream 1  | Analog In Data                      |\n",
    "| Analog Stream 2  | Digital In/Out Data                 |\n",
    "| Event Stream 0   | Digital In/Out Events, Stimulation Events  |\n",
    "| Event Stream 1   | Experiment Timing Events            |\n",
    "| Event Stream 2   | Treatment Timing Events             |\n",
    "\n",
    "For the purposes of this tutorial, only Analog Stream 0 is relevant because it holds the recorded neuronal data. The other streams, especially the event streams, become important as soon as you are working with stimulation and need the stimulation timestamps (Event Stream 0) or if you are analyzing Multiwell-MEA data recorded from experiments with multiple phases, e.g. if recorded a dilution series for a compound. In this case, Event Stream 1 and 2 will give you the timestamps of each phase in the experiment. However, because only a single phase was recorded here and no stimulation was used, Analog Stream 0 will suffice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = McsPy.McsData.RawData(file_path)\n",
    "electrode_stream = file.recordings[0].analog_streams[0];"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "Let's define a plot function to plot a single channel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_analog_stream_channel(analog_stream, channel_idx, from_in_s=0, to_in_s=None, show=True):\n",
    "    \"\"\"\n",
    "    Plots data from a single AnalogStream channel\n",
    "    \n",
    "    :param analog_stream: A AnalogStream object\n",
    "    :param channel_idx: A scalar channel index (0 <= channel_idx < # channels in the AnalogStream)\n",
    "    :param from_in_s: The start timestamp of the plot (0 <= from_in_s < to_in_s). Default: 0\n",
    "    :param to_in_s: The end timestamp of the plot (from_in_s < to_in_s <= duration). Default: None (= recording duration)\n",
    "    :param show: If True (default), the plot is directly created. For further plotting, use show=False\n",
    "    \"\"\"\n",
    "    # extract basic information\n",
    "    ids = [c.channel_id for c in analog_stream.channel_infos.values()]\n",
    "    channel_id = ids[channel_idx]\n",
    "    channel_info = analog_stream.channel_infos[channel_id]\n",
    "    sampling_frequency = channel_info.sampling_frequency.magnitude\n",
    "   \n",
    "    # get start and end index\n",
    "    from_idx = max(0, int(from_in_s * sampling_frequency))\n",
    "    if to_in_s is None:\n",
    "        to_idx = analog_stream.channel_data.shape[1]\n",
    "    else:\n",
    "        to_idx = min(analog_stream.channel_data.shape[1], int(to_in_s * sampling_frequency))\n",
    "        \n",
    "    # get the timestamps for each sample\n",
    "    time = analog_stream.get_channel_sample_timestamps(channel_id, from_idx, to_idx)\n",
    "\n",
    "    # scale time to seconds:\n",
    "    scale_factor_for_second = Q_(1,time[1]).to(ureg.s).magnitude\n",
    "    time_in_sec = time[0] * scale_factor_for_second\n",
    "    \n",
    "    # get the signal\n",
    "    signal = analog_stream.get_channel_in_range(channel_id, from_idx, to_idx)\n",
    "\n",
    "    # scale signal to µV:\n",
    "    scale_factor_for_uV = Q_(1,signal[1]).to(ureg.uV).magnitude\n",
    "    signal_in_uV = signal[0] * scale_factor_for_uV\n",
    "\n",
    "    # construct the plot\n",
    "    _ = plt.figure(figsize=(20,6))\n",
    "    _ = plt.plot(time_in_sec, signal_in_uV)\n",
    "    _ = plt.xlabel('Time (%s)' % ureg.s)\n",
    "    _ = plt.ylabel('Voltage (%s)' % ureg.uV)\n",
    "    _ = plt.title('Channel %s' % channel_info.info['Label'])\n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we can have a look at different channels (feel free to play around with the channel index and the time range):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analog_stream_channel(electrode_stream, 0, from_in_s=0, to_in_s=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this tutorial, we are going to work with the channel with index ``9`` and ID ``171``. In the MEA well, this channel was at position ``'43'``. We chose this channel because it exhibits nice multi-unit activity which is perfect for a tutorial on spike sorting. Looking at a short time segment for this channel, we can clearly see spikes of vastly different amplitudes which most likely stem from different neurons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_analog_stream_channel(electrode_stream, 9, from_in_s=155, to_in_s=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on the bandwidth of the recording, it can be necessary to perform a bandpass filtering in order to remove low-frequency fluctuations. A bandpass filter with cutoffs ``[100, 3500] Hz`` had been applied during the recording of this dataset, so no further filtering is necessary here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_id = 171\n",
    "info = electrode_stream.channel_infos[channel_id].info\n",
    "print(\"Bandwidth: %s - %s Hz\" % (info['HighPassFilterCutOffFrequency'], info['LowPassFilterCutOffFrequency']))\n",
    "\n",
    "signal = electrode_stream.get_channel_in_range(channel_id, 0, electrode_stream.channel_data.shape[1])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike Detection\n",
    "\n",
    "Our first task is going to be to detect spikes on the data channel and extract cutouts of the spike waveforms. \n",
    "\n",
    "Usually, the easiest way to get these spike waveforms would be to perform the spike detection in the MCS software, export them together with the recorded raw data to HDF5 and then simply access them with the McsPy tools. These spike waveforms would be stored as a ``SegmentStream`` (see the basic toolbox tutorial for more information on interacting with ``SegmentStream``s).\n",
    "\n",
    "However, for tutorial purposes, let's say we want to redo the spike detection in Python. We use a very simple threshold-based spike detection here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to determine a suitable threshold for spike detection. A reasonable way to do this is to estimate the noise level of the channel, and then use a multiple of the noise level as the threshold (a multiplication factor of 5 tends to work quite well). While we could estimate the noise level from the standard deviation of the signal, this has the drawback that the spikes in the signal can have a strong influence on the standard deviation and lead to an unnecessarily high threshold. The MAD estimator is more robust against outlier and might therefore be more appropriate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_std = np.std(signal)\n",
    "noise_mad = np.median(np.absolute(signal)) / 0.6745\n",
    "print('Noise Estimate by Standard Deviation: {0:g} V'.format(noise_std))\n",
    "print('Noise Estimate by MAD Estimator     : {0:g} V'.format(noise_mad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the difference between the two is about 3 µV, so we'll stick with the MAD estimator. We are using a negative threshold here, so we are just looking at the negative peak of each spike."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_threshold = -5 * noise_mad # roughly -30 µV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the same data section as above together with the spike threshold. We are detecting some very small spikes with this threshold, so depending on your aim you may want to increase the multiplication factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_analog_stream_channel(electrode_stream, 9, from_in_s=155, to_in_s=200, show=False)\n",
    "_ = plt.plot([155, 200], [spike_threshold*1e6, spike_threshold*1e6]) # converts the threshold to µV for plotting\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our spike detector needs to take into account that a spike typically comprises multiple samples, so we can't simply take each sample that exceeds the threshold as an individual spike detection. Instead, we'll define a *dead time*, meaning that whenever we detect a spike, the next few samples within the dead time won't trigger a spike detection by themselves. \n",
    "\n",
    "In order to reduce the detection jitter, we additionally search for each spike the minimum in the signal for a short period of time after the threshold crossing. This will be the timestamp for each spike. We'll define some helper functions to achieve this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_threshold_crossings(signal, fs, threshold, dead_time):\n",
    "    \"\"\"\n",
    "    Detect threshold crossings in a signal with dead time and return them as an array\n",
    "    \n",
    "    The signal transitions from a sample above the threshold to a sample below the threshold for a detection and\n",
    "    the last detection has to be more than dead_time apart from the current one.\n",
    "    \n",
    "    :param signal: The signal as a 1-dimensional numpy array\n",
    "    :param fs: The sampling frequency in Hz\n",
    "    :param threshold: The threshold for the signal\n",
    "    :param dead_time: The dead time in seconds. \n",
    "    \"\"\"\n",
    "    dead_time_idx = dead_time * fs\n",
    "    threshold_crossings = np.diff((signal <= threshold).astype(int) > 0).nonzero()[0]\n",
    "    distance_sufficient = np.insert(np.diff(threshold_crossings) >= dead_time_idx, 0, True)\n",
    "    while not np.all(distance_sufficient):\n",
    "        # repeatedly remove all threshold crossings that violate the dead_time\n",
    "        threshold_crossings = threshold_crossings[distance_sufficient]\n",
    "        distance_sufficient = np.insert(np.diff(threshold_crossings) >= dead_time_idx, 0, True)\n",
    "    return threshold_crossings\n",
    "\n",
    "def get_next_minimum(signal, index, max_samples_to_search):\n",
    "    \"\"\"\n",
    "    Returns the index of the next minimum in the signal after an index\n",
    "    \n",
    "    :param signal: The signal as a 1-dimensional numpy array\n",
    "    :param index: The scalar index \n",
    "    :param max_samples_to_search: The number of samples to search for a minimum after the index\n",
    "    \"\"\"\n",
    "    search_end_idx = min(index + max_samples_to_search, signal.shape[0])\n",
    "    min_idx = np.argmin(signal[index:search_end_idx])\n",
    "    return index + min_idx\n",
    "\n",
    "def align_to_minimum(signal, fs, threshold_crossings, search_range):\n",
    "    \"\"\"\n",
    "    Returns the index of the next negative spike peak for all threshold crossings\n",
    "    \n",
    "    :param signal: The signal as a 1-dimensional numpy array\n",
    "    :param fs: The sampling frequency in Hz\n",
    "    :param threshold_crossings: The array of indices where the signal crossed the detection threshold\n",
    "    :param search_range: The maximum duration in seconds to search for the minimum after each crossing\n",
    "    \"\"\"\n",
    "    search_end = int(search_range*fs)\n",
    "    aligned_spikes = [get_next_minimum(signal, t, search_end) for t in threshold_crossings]\n",
    "    return np.array(aligned_spikes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's perform the spike detection using our detector with dead time. Then, we align the spikes to their negative peaks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = int(electrode_stream.channel_infos[channel_id].sampling_frequency.magnitude)\n",
    "crossings = detect_threshold_crossings(signal, fs, spike_threshold, 0.003) # dead time of 3 ms\n",
    "spks = align_to_minimum(signal, fs, crossings, 0.002) # search range 2 ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To double check, let's plot the signal together with the detected spikes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = spks / fs\n",
    "range_in_s = (155, 200)\n",
    "spikes_in_range = timestamps[(timestamps >= range_in_s[0]) & (timestamps <= range_in_s[1])]\n",
    "\n",
    "plot_analog_stream_channel(electrode_stream, 9, from_in_s=range_in_s[0], to_in_s=range_in_s[1], show=False)\n",
    "_ = plt.plot(spikes_in_range, [spike_threshold*1e6]*spikes_in_range.shape[0], 'ro', ms=2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spike Waveforms\n",
    "\n",
    "Having found the spike timestamps, we may now extract the spike waveforms. For this, we simply cut out a portion of the signal around each spike. Spikes too close to the start or end of the signal that a full cutout is not possible are ignored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_waveforms(signal, fs, spikes_idx, pre, post):\n",
    "    \"\"\"\n",
    "    Extract spike waveforms as signal cutouts around each spike index as a spikes x samples numpy array\n",
    "    \n",
    "    :param signal: The signal as a 1-dimensional numpy array\n",
    "    :param fs: The sampling frequency in Hz\n",
    "    :param spikes_idx: The sample index of all spikes as a 1-dim numpy array\n",
    "    :param pre: The duration of the cutout before the spike in seconds\n",
    "    :param post: The duration of the cutout after the spike in seconds\n",
    "    \"\"\"\n",
    "    cutouts = []\n",
    "    pre_idx = int(pre * fs)\n",
    "    post_idx = int(post * fs)\n",
    "    for index in spikes_idx:\n",
    "        if index-pre_idx >= 0 and index+post_idx <= signal.shape[0]:\n",
    "            cutout = signal[(index-pre_idx):(index+post_idx)]\n",
    "            cutouts.append(cutout)\n",
    "    return np.stack(cutouts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = 0.001 # 1 ms\n",
    "post= 0.002 # 2 ms\n",
    "cutouts = extract_waveforms(signal, fs, spks, pre, post)\n",
    "print(\"Cutout array shape: \" + str(cutouts.shape)) # number of spikes x number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot an overlay of the extracted cutouts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_waveforms(cutouts, fs, pre, post, n=100, color='k', show=True):\n",
    "    \"\"\"\n",
    "    Plot an overlay of spike cutouts\n",
    "    \n",
    "    :param cutouts: A spikes x samples array of cutouts\n",
    "    :param fs: The sampling frequency in Hz\n",
    "    :param pre: The duration of the cutout before the spike in seconds\n",
    "    :param post: The duration of the cutout after the spike in seconds\n",
    "    :param n: The number of cutouts to plot, or None to plot all. Default: 100\n",
    "    :param color: The line color as a pyplot line/marker style. Default: 'k'=black\n",
    "    :param show: Set this to False to disable showing the plot. Default: True\n",
    "    \"\"\"\n",
    "    if n is None:\n",
    "        n = cutouts.shape[0]\n",
    "    n = min(n, cutouts.shape[0])\n",
    "    time_in_us = np.arange(-pre*1000, post*1000, 1e3/fs)\n",
    "    if show:\n",
    "        _ = plt.figure(figsize=(12,6))\n",
    "    \n",
    "    for i in range(n):\n",
    "        _ = plt.plot(time_in_us, cutouts[i,]*1e6, color, linewidth=1, alpha=0.3)\n",
    "        _ = plt.xlabel('Time (%s)' % ureg.ms)\n",
    "        _ = plt.ylabel('Voltage (%s)' % ureg.uV)\n",
    "        _ = plt.title('Cutouts')\n",
    "    \n",
    "    if show:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_waveforms(cutouts, fs, pre, post, n=250)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this waveform overlay it seems clear that the spikes we are seeing stem from (at least) two different neurons. In order to determine, which spikes stem from the same neuron, we need to analyze these cutouts further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction\n",
    "\n",
    "We would expect that we should be able to distinguish the spikes from different neurons based on the shape of the spike waveform. So we now need a way to find a good representation of the waveform shape. \"Good\" means in this case that the result should be well separable, i.e. that similar waveforms are represented close to each other and far away from dissimilar waveforms. In addition, the representation should have as few dimensions as possible because the clustering step tends to work better if there aren't too many dimensions involved.\n",
    "\n",
    "This is commonly called the *Feature Extraction* step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could try to manually design some features that seem useful. For example, we could take the minimum and maximum amplitude and try to work with those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_amplitude = np.amin(cutouts, axis=1)\n",
    "max_amplitude = np.amax(cutouts, axis=1)\n",
    "\n",
    "_ = plt.figure(figsize=(8,8))\n",
    "_ = plt.plot(min_amplitude*1e6, max_amplitude*1e6,'.')\n",
    "_ = plt.xlabel('Min. Amplitude (%s)' % ureg.uV)\n",
    "_ = plt.ylabel('Max. Amplitude (%s)' % ureg.uV)\n",
    "_ = plt.title('Min/Max Spike Amplitudes')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can directly see some distinct clusters in this plot which might represent spikes from different neuronal sources, but a lot of spikes are closely bunched together in the lower right corner. Taking only the minimum and maximum amplitude might be a bit too simplistic, because for example judging from the cutout overlay plot, the maximum can happen before or after time point 0 and with similar values. Using the amplitude alone won't differentiate between these different shapes. \n",
    "\n",
    "More sophisticated feature design could remedy this, but there are also more general feature extraction methods available that require less manual interaction. A widespread method for this is principal component analysis ([PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html)). It finds a linear transformation of the data into principal component space, thereby decorrelating the data. Because each principle component (PC) explains as much variance in the data as possible (while being orthogonal to all previous principal components), we can use the explained variance as a measure of the  \"importance\" of each PC. This will help us decide, how many dimensions (= PCs) we need to keep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaled_cutouts = scaler.fit_transform(cutouts)\n",
    "\n",
    "pca = PCA()\n",
    "pca.fit(scaled_cutouts)\n",
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the first 2 PCs together explain 49.6 % + 18.7 % = 67.3 % of the variance in the data. This might be enough, so we will now project our cutouts on the first 2 PCs, giving us only 2 coefficients for each spike: The weight of the 1st and the 2nd PC. These coefficients are dimensionless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components = 2\n",
    "transformed = pca.fit_transform(scaled_cutouts)\n",
    "\n",
    "_ = plt.figure(figsize=(8,8))\n",
    "_ = plt.plot(transformed[:,0], transformed[:,1],'.')\n",
    "_ = plt.xlabel('Principal Component 1')\n",
    "_ = plt.ylabel('Principal Component 2')\n",
    "_ = plt.title('PC1 vs PC2')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see 4 quite well defined clusters in the dataset. Out of curiosity, we can also test what happens if we take the first 3 PCs instead of 2 (although this makes the visualization a bit more tricky):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca.n_components = 3\n",
    "transformed_3d = pca.fit_transform(scaled_cutouts)\n",
    "\n",
    "_ = plt.figure(figsize=(15,5))\n",
    "_ = plt.subplot(1, 3, 1)\n",
    "_ = plt.plot(transformed_3d[:,0], transformed_3d[:,1],'.')\n",
    "_ = plt.xlabel('Principal Component 1')\n",
    "_ = plt.ylabel('Principal Component 2')\n",
    "_ = plt.title('PC1 vs PC2')\n",
    "_ = plt.subplot(1, 3, 2)\n",
    "_ = plt.plot(transformed_3d[:,0], transformed_3d[:,2],'.')\n",
    "_ = plt.xlabel('Principal Component 1')\n",
    "_ = plt.ylabel('Principal Component 3')\n",
    "_ = plt.title('PC1 vs PC3')\n",
    "_ = plt.subplot(1, 3, 3)\n",
    "_ = plt.plot(transformed_3d[:,1], transformed_3d[:,2],'.')\n",
    "_ = plt.xlabel('Principal Component 2')\n",
    "_ = plt.ylabel('Principal Component 3')\n",
    "_ = plt.title('PC2 vs PC3')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering\n",
    "\n",
    "Now to the final step: Finding clusters in the feature space and assigning each spike to its closest cluster. There are [many, many](https://scikit-learn.org/stable/modules/clustering.html) clustering algorithms out there, but we will use a very simple one: A Gaussian Mixture Model ([GMM](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html#sklearn.mixture.GaussianMixture)). Of course, GMMs have their drawbacks (number of clusters must be specified, many parameters to fit, don't scale very well), but for our case they might be sufficient.\n",
    "\n",
    "Judging from our plot, 4 clusters might be sufficient as a description of the data. The initialization of a GMM can have a lot of influence on the output, so it is possible that you need to fit the GMM multiple times in order to find a good fit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components = 4\n",
    "gmm = GaussianMixture(n_components=n_components, n_init=10)\n",
    "labels = gmm.fit_predict(transformed)\n",
    "\n",
    "_ = plt.figure(figsize=(8,8))\n",
    "for i in range(n_components):\n",
    "    idx = labels == i\n",
    "    _ = plt.plot(transformed[idx,0], transformed[idx,1],'.')\n",
    "    _ = plt.title('Cluster assignments by a GMM')\n",
    "    _ = plt.xlabel('Principal Component 1')\n",
    "    _ = plt.ylabel('Principal Component 2')\n",
    "    _ = plt.axis('tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we've found a sensible clustering, we can now go back and check the waveforms in the different clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(8,8))\n",
    "for i in range(n_components):\n",
    "    idx = labels == i\n",
    "    color = plt.rcParams['axes.prop_cycle'].by_key()['color'][i]\n",
    "    plot_waveforms(cutouts[idx,:], fs, pre, post, n=100, color=color, show=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This concludes this short tutorial on neuronal data analysis with the McsPyDataTools package."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "McsPyDataTools Tutorial<a id='Top'></a>\n",
    "=======================\n",
    "\n",
    "- <a href='#D and I'>Downloading and installing</a>\n",
    "---------------------------------------------------\n",
    "- <a href='#Mcs-HDF5'>Structure of the Mcs-HDF5 file</a>\n",
    "--------------------------------------------------------\n",
    "- <a href='#McsData Module'>McsData Classes and Inheritance</a>\n",
    "-------------------------------------------------------------------------------------------\n",
    " - ### <a href='#RD'>RawData</a> \n",
    " - ### <a href='#R'>Recording</a> \n",
    " - ### <a href='#S'>Stream</a>\n",
    " - ### <a href='#I'>Info</a> \n",
    "  \n",
    "- <a href='#Accessing your Data with McsData'>Accessing your Data with McsData</a>\n",
    "----------------------------------------------------------------------------------\n",
    " - ### <a href='#Req'>Requirements</a>\n",
    " - ### <a href='#AS'>AnalogStream</a>\n",
    " - ### <a href='#FS'>FrameStream</a>\n",
    " - ### <a href='#ES'>EventStream</a>\n",
    " - ### <a href='#SS'>SegmentStream</a>\n",
    "  - #### <a href='#SC'>Subtype: Cutouts</a>\n",
    "  - #### <a href='#SA'>Subtype: Averages</a>\n",
    " - ### <a href='#TS'>TimestampStream</a>\n",
    " - ### <a href='#I2'>Info</a>\n",
    "\n",
    "   \n",
    "- <a href='#Accessing your Data with McsCMOS'>Accessing your Data with McsCMOS</a>\n",
    "---------------------------------------------------------------------------------- \n",
    " - ### <a href='#CD'>CMOSData</a>\n",
    "\n",
    "\n",
    "Downloading and installing<a id='D and I'></a>\n",
    "----------------------------------------------\n",
    "\n",
    "Open a console or terminal and\n",
    "\n",
    "### - With pip or setuptools\n",
    "\n",
    "type:\n",
    "\n",
    "    pip install McsPyDataTools\n",
    "    \n",
    "Or if you have setuptools installed type:\n",
    "\n",
    "    easy_install McsPyDataTools\n",
    "    \n",
    "\n",
    "If this doesn't yield the expected result, download the file from:\n",
    "\n",
    "http://download.multichannelsystems.com/download_data/software/multi_channel_suite/datamanager/McsPyDataTools-0.2.3.zip\n",
    "\n",
    "From here there are 4 possible ways to get the module working.\n",
    "\n",
    "\n",
    "### - Manually(while packed)\n",
    " \n",
    "Go to your Downloads folder and run:\n",
    "    \n",
    "    pip install McsPyDataTools-0.2.3.zip   \n",
    "    \n",
    "Or if you have setuptools installed:\n",
    "\n",
    "    easy_install McsPyDataTools-0.2.3.zip   \n",
    "    \n",
    "\n",
    "If the methods above fail, unpack the .zip file.\n",
    "\n",
    "### - Manually(when unpacked) I\n",
    "\n",
    "Go to the folder you unpacked the module to and run:\n",
    "    \n",
    "    pip install McsPyDataTools-0.2.3\n",
    "    \n",
    "Or if you have setuptools installed:\n",
    "\n",
    "    easy_install McsPyDataTools-0.2.3\n",
    "    \n",
    "    \n",
    "### - Manually(when unpacked) II\n",
    "\n",
    "Go to the folder you unpacked the module to, go to the McsPyDataTools_0.2.3 folder and run the **setup.py** file from inside the folder\n",
    "\n",
    "    python setup.py install\n",
    "    \n",
    "\n",
    "If either of the above worked there will be an **McsPyDataTools-0.2.3-py3.6.egg** \n",
    "<!-- **McsPyDataTools-0.2.3.dist-info** **McsPyDataTools-0.2.3-py2.7.egg** ?? --> \n",
    "in the site_package folder aswell as an **McsPyDataTools.py** and a **PlotExperimentData.py** script in the Scripts folder of your Python installation.\n",
    "    \n",
    "    \n",
    "### - Manually(when unpacked) III\n",
    "\n",
    "If the other ways fail or you are still unable to import the module into a python script, you can manually place the **McsData.py** and **McsCMOS.py** scripts from the McsPyDataTools folder in the **\\site-packages** folder of your Python installation.\n",
    "\n",
    "Note that the folder containing your Python installation might be hidden.\n",
    "\n",
    "This last option will only make the classes availible needed to analyze HDF5 files. Any other scripts, like the **DataStreamInfo.py** or the **McsDataTools.py** script, which should get installed to the **/Scripts** folder of your python installation, are best copied into a seperate folder.\n",
    "\n",
    "### Data\n",
    "\n",
    "<!-- This notebook relies on some files which hold the data for the examples. These are quiet large and would exceed the repositories size limt. Therefor the files can be separately downloaded here:\n",
    "\n",
    "\n",
    "# DOWNLOADLINK  FÜR DATEN HIER EINFÜGEN -->\n",
    "\n",
    "This notebook relies on some files which hold the data for the examples. These files are quite large and can be found in the subfolder **TestData** of this archive.\n",
    "\n",
    "<a href='#Top'>Back to index</a>\n",
    "\n",
    "Structure of the Mcs-HDF5 file<a id='Mcs-HDF5'></a>\n",
    "---------------------------------------------------\n",
    "\n",
    "With the included **DataStreamInfo.py** script,  a first look can be taken at what the HDF5 file contains.\n",
    "\n",
    "The information about the data within the file can be viewed by calling the **DataStreamInfo.py** script from the console and handing over the exact file-path with the argument for directory and filepath: **-f**\n",
    "\n",
    "\n",
    "    X:\\...\\python DataStreamInfo.py -f \"X:\\Data\\Experiment_231\\2014-07-09T10-17-35W8 Standard all 500 Hz.h5\" \n",
    "    \n",
    "If the desired file is in the same folder as **DataStreamInfo.py**, you might want to consider copying this script to your datafolder, **--f + \"Filename\"** can be used:\n",
    "\n",
    "    X:\\...\\python DataStreamInfo.py --f \"2014-07-09T10-17-35W8 Standard all 500 Hz.h5\"\n",
    "    \n",
    "A tabel like this will appear:\n",
    "\n",
    "    2014-07-09T10-17-35W8 Standard all 500 Hz.h5\n",
    "\n",
    "    Date                 Program                     Version\n",
    "    -------------------  --------------------------  ---------\n",
    "    2014-07-09 10:17:35  Multi Channel Experimenter  0.9.8.2\n",
    "    \n",
    "    Type       Stream                                   # ch\n",
    "    ---------  ---------------------------------------  ------\n",
    "    Analog     Filter (1) Filter Data                   8\n",
    "    Analog     Data Acquisition (1) Electrode Raw Data  8\n",
    "    Analog     Data Acquisition (1) Digital Data        1\n",
    "    Event      Digital Events 1\n",
    "    Segment    Spike Detector (1) Spike Data\n",
    "    TimeStamp  Spike Detector (1) Spike Timestamps\n",
    "    \n",
    "It holds information about the **Date** of the recording, the **Program** which was used as well as its **Version**. Also included is a list of **Streams** and additional information concerning these. Streams can be seen as containers of information of a certain type.\n",
    "\n",
    "<a href='#Top'>Back to index</a>\n",
    "\n",
    "McsData Classes and Inheritance <a id='McsData Module'></a>\n",
    "---------------------------------------------------------------------------------------\n",
    "\n",
    "This is a graphical representation of the classes and their content which may be found in an HDF5 file produced by Mcs apparatuses.\n",
    "\n",
    "<img src=\"./Hierarchy_short.png\">\n",
    "\n",
    "Additional information about the membermethods of each class can be found in **McsData.py** or the module description file.\n",
    "\n",
    "We also highly recomend the use of the HDF Groups **HDFView** software to help visualize and understand the structure of HDF5 files. This can make accessing the data **MUCH** easier.\n",
    "\n",
    "<a href='#Top'>Back to index</a>\n",
    "\n",
    "### RawData  <a id='RD'></a>\n",
    "\n",
    "As the docstrings of the class already imply, this class was designed to hold the information of a complete MCS raw data file. \n",
    "\n",
    "Upon initialization with the path to your rawdata\n",
    "\n",
    "```python\n",
    "    rawdata = RawData('path to your rawdata')\n",
    "```\n",
    "\n",
    "membermethods of this class will check if the provided file meets the version requirements to be further processesed. This is neccessary, as not only the way how Mcs programs handle the HDF5 formated files may change but the fileformat itself can undergo changes.\n",
    "\n",
    "```python\n",
    "    self.__validate_mcs_hdf5_version()\n",
    "```\n",
    "\n",
    "Afterwards all information about the data stored in the file is retrieved.\n",
    "\n",
    "```python\n",
    "    self.__get_session_info()\n",
    "```\n",
    "\n",
    "When needed all recordings from the rawdata file are read by\n",
    "\n",
    "```python\n",
    "    self.__read_recordings()\n",
    "```\n",
    "\n",
    "This generates a dictionary with the number of the recordings as keys, Recording\\_**0**, Recording\\_**1**, etc. and the values as members of the Recording class with the correspondigng data. This will be important when we will discuss the possibility of iterating over all datasets within one group.\n",
    "\n",
    "<a href='#Top'>Back to index</a>\n",
    "\n",
    "### Recording  <a id='R'></a>\n",
    "\n",
    "The Recording class can be seen as a container for all the data gathered in one recording.\n",
    "\n",
    "```python\n",
    "    class RawData(object):\n",
    "    \n",
    "        ...\n",
    "        \n",
    "        self.__recordings[int(recording_name[1])] = Recording(value)\n",
    "```\n",
    "\n",
    "Upon initialization the values extracted by the RawData class got asigned to it.\n",
    "\n",
    "```python\n",
    "    class Recording(object):\n",
    "    \n",
    "        ...\n",
    "        \n",
    "        self.__recording_grp = recording_grp  # recording_grp = value\n",
    "```\n",
    "Later on these can be further decomposed by the membermethods of this class into the different subtypes/children of the Stream class.\n",
    "\n",
    "```python\n",
    "    self.__read_analog_streams()\n",
    "    self.__read_frame_streams()\n",
    "    self.__read_event_streams()\n",
    "    self.__read_segment_streams()\n",
    "    self.__read_timestamp_streams()\n",
    "```     \n",
    "    \n",
    "The data of the streams gets assigned in a similar fashion as seen before with the recordings\n",
    "\n",
    "```python\n",
    "    class Recording(object):\n",
    "\n",
    "        ...\n",
    "        \n",
    "        if 'AnalogStream' in self.__recording_grp:\n",
    "            \n",
    "            ...\n",
    "        \n",
    "            self.__analog_streams[int(stream_name[1])] = AnalogStream(value)\n",
    "        \n",
    "    \n",
    "    \n",
    "    class AnalogStream(Stream):\n",
    "    \n",
    "        ...\n",
    "        \n",
    "        Stream.__init__(self, stream_grp, \"AnalogStreamInfoVersion\")  # stream_grp = value\n",
    "```\n",
    "\n",
    "Due to this internal structure of classes and subclasses, beeing only created when addressed, only smal portions of the data ever get loaded at any time, making the access and the computation of those values so fast.\n",
    "\n",
    "<a href='#Top'>Back to index</a>\n",
    "\n",
    "### Stream <a id='S'></a>\n",
    "\n",
    "The Stream class is the base class from which all stream types inherit. All describing metadata of the stream is read here.\n",
    "\n",
    "Currently the following types exist:\n",
    " - AnalogStream\n",
    " - FrameStream\n",
    " - EventStream\n",
    " - SegmentStream\n",
    " - TimeStampStream\n",
    " \n",
    "These streams can be further split up into single entityies of the corresponding type. So FrameStream can habour several FrameEntities. These Entities finaly hold the data which, once addressed, can be viewed, manipulated and/or visualized.\n",
    "\n",
    "Additional information about the classes can be found in the html-Documentation.\n",
    "\n",
    "<a href='#Top'>Back to index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Info <a id='I'></a>\n",
    "\n",
    "Additionally to the Stream classes, there is the Info class.\n",
    "This is the parent class of all Info child classes that exist for the different Stream types. Info that gets stored can be timerange of ticks, units of readings, experiment specific information about dilutions, sensor id, filtersettings, etc..\n",
    "\n",
    "<a href='#Top'>Back to index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing your Data with McsData<a id='Accessing your Data with McsData'></a>\n",
    "\n",
    "Now that the mechanism of reading data from an HDF5 file with the classes included in the McsData module is clear we can walk through some quick and easy examples of how to access and visualize your data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Requirements <a id='Req'></a>\n",
    "\n",
    "First some modules need to be imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the imports of the McsData module\n",
    "import sys, importlib\n",
    "sys.path.append('D:\\\\Programming\\\\McsDataManagement\\\\McsPyDataTools\\\\McsPyDataTools')\n",
    "import McsPy.McsData\n",
    "import McsPy.McsCMOS\n",
    "from McsPy import ureg, Q_\n",
    "\n",
    "# matplotlib.pyplot will be used in these examples to generate the plots visualizing the data\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.figure import Figure\n",
    "from matplotlib.widgets import Slider\n",
    "# These adjustments only need to be made so that the plot gets displayed inside the notebook\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_formats = {'png', 'retina'}\n",
    "\n",
    "# numpy is numpy ...\n",
    "import numpy as np\n",
    "\n",
    "# bokeh adds more interactivity to the plots within notebooks. Adds toolbar at the top-right corner of the plot.\n",
    "# Allows zooming, panning and saving of the plot\n",
    "import bokeh.io\n",
    "import bokeh.plotting\n",
    "from bokeh.palettes import Spectral11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes running Python applications in the background can interfere with the functionalities of this notebook. To make sure that all plots are created correctly you are best advised to exit any other Python related processes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Top'>Back to index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AnalogStream<a id='AS'></a>\n",
    "\n",
    "Next we need to access the rawdata by initializing an instance of the RawData class from the McsData module by handing over the path to the file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filepath points to the folder TestData within the folder, where this notebook resides.\n",
    "\n",
    "To check if we got acces to the file we can look at its contents by printing the info that got extracted when the RawData object was initialized. This is just for demonstrational purposes and does not need to be made every time data is accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_raw_data = McsPy.McsData.RawData('.\\\\TestData\\\\2014-07-09T10-17-35W8 Standard all 500 Hz.h5')\n",
    "#channel_raw_data = McsPy.McsData.RawData('D:\\\\Programming\\\\McsDataManagement\\\\McsPyDataTools\\\\TestData\\\\2014-07-09T10-17-35W8 Standard all 500 Hz.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_raw_data.comment)\n",
    "print(channel_raw_data.date)\n",
    "print(channel_raw_data.clr_date)\n",
    "print(channel_raw_data.date_in_clr_ticks)\n",
    "print(channel_raw_data.file_guid)\n",
    "print(channel_raw_data.mea_name)\n",
    "print(channel_raw_data.mea_sn)\n",
    "print(channel_raw_data.mea_layout)\n",
    "print(channel_raw_data.program_name)\n",
    "print(channel_raw_data.program_version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_raw_data.recordings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_raw_data.recordings[0].analog_streams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, the indices or IDs of the included datastructures can be addressed by calling **.keys()** on the HDF5 groups. This is due to the fact that inside of McsData, upon initialization of the different datastructure-types, dictionaries are created with IDs as keys and values of the data as values.\n",
    "\n",
    "This will become more important later in this tutorial when the procedure of iterating over all data of one stream is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_raw_data.recordings.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that there is one Recording within the rawdata with index 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_raw_data.recordings[0].analog_streams.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and it includes 3 AnalogStreams at index 0,1 and 2\n",
    "\n",
    "    (u'Stream_0', <HDF5 group \"/Data/Recording_0/AnalogStream/Stream_0\" (3 members)>)\n",
    "    (u'Stream_1', <HDF5 group \"/Data/Recording_0/AnalogStream/Stream_1\" (3 members)>)\n",
    "    (u'Stream_2', <HDF5 group \"/Data/Recording_0/AnalogStream/Stream_2\" (3 members)>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the file with **DataStreamInfo.py** we know what these streams are.\n",
    "\n",
    "    Type       Stream                                   # ch\n",
    "    ---------  ---------------------------------------  ------\n",
    "    Analog     Filter (1) Filter Data                   8      <----- Index: 0\n",
    "    Analog     Data Acquisition (1) Electrode Raw Data  8\n",
    "    Analog     Data Acquisition (1) Digital Data        1\n",
    "\n",
    "\n",
    "So the first of the three streams is addressed like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_stream_0 = channel_raw_data.recordings[0].analog_streams[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data of the stream can be found under **.channel_data**. It is only now that the actual values from the data get accessed. Before this step, we only navigated through pointers of sorts containing information leading to the data. This behavior makes working with HDF5 so efficient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analog_stream_0_data = analog_stream_0.channel_data\n",
    "\n",
    "print(analog_stream_0_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By rearanging the dimensions of the data-array with the numpy function **transpose()** it's dimensions are more suitable for plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_analog_stream_0_data = np.transpose(analog_stream_0_data)\n",
    "\n",
    "print(\"Old shape:\", analog_stream_0_data.shape)\n",
    "print(\"New shape:\", np_analog_stream_0_data.shape)\n",
    "print()\n",
    "print(np_analog_stream_0_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np_analog_stream_0_data)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Refined plots with added lables and title might look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(np_analog_stream_0_data)\n",
    "plt.title('Signal for Wireless (Simulation) / Raw ADC-Values (%s)' % analog_stream_0.label)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('ADC Value')\n",
    "plt.grid()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to look at certain portions of the data this can be achieved by specifying a range when accessing it.\n",
    "\n",
    "To specify a range it helps to know the shape of your data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_analog_stream_0_data = np.transpose(channel_raw_data.recordings[0].analog_streams[0].channel_data)\n",
    "\n",
    "print(np_analog_stream_0_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that this data-array has 9850 rows and 8 columns. \n",
    "\n",
    "Let's look at **rows 4400 to 4800** in **columns 4 to 7**. Notice that in the HDF5 file rows and colums are swapped. As python doesn't include the last item in range we have to add 1 to both ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np_data_range = np_analog_stream_0_data[4500:4801, 4:8]  \n",
    "\n",
    "print(np_data_range)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then just plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.output_notebook()  # see comment for bokeh module in \"Requirements\" section\n",
    "bfig = bokeh.plotting.figure(plot_width=900, plot_height=400, title='Signal for Wireless (Simulation) / Raw ADC-Values (%s)' % analog_stream_0.label)\n",
    "bfig.multi_line(\n",
    "    xs = [list(range(np_data_range.shape[0]))] * np_data_range.shape[1],\n",
    "    ys = [np_data_range[:, col] for col in range(np_data_range.shape[1])],\n",
    "    line_color = Spectral11[0:np_data_range.shape[1]],\n",
    "    alpha = 0.8\n",
    ")\n",
    "#bfig.line(list(range(np_data_range.shape[0])),np_data_range[:,0], alpha=0.5)\n",
    "bfig.xaxis.axis_label = 'Sample Index'\n",
    "bfig.yaxis.axis_label = 'ADC Value'\n",
    "bfig.ygrid.minor_grid_line_color = 'navy'\n",
    "bfig.ygrid.minor_grid_line_alpha = 0.1\n",
    "bokeh.plotting.show(bfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course other plot-types can be used if desired. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Draw channel with spectogram:\n",
    "\n",
    "With the values from the second AnalogStream, \n",
    "\n",
    "    Type       Stream                                   # ch\n",
    "    ---------  ---------------------------------------  ------\n",
    "    Analog     Filter (1) Filter Data                   8\n",
    "    Analog     Data Acquisition (1) Electrode Raw Data  8      <------   \n",
    "    Analog     Data Acquisition (1) Digital Data        1\n",
    "    Event      Digital Events 1\n",
    "    Segment    Spike Detector (1) Spike Data\n",
    "    TimeStamp  Spike Detector (1) Spike Timestamps\n",
    "\n",
    "With **.get_channel_in_range(channel_id, index_start, index_end)** and **.get_channel_sample_timestamps(channel_id, index_start, index_end)** we can define a range of data and timestamps, from **index_start** to **index_end** for a specific channel with **channel_id** that we want to analyze/plot.\n",
    "\n",
    "However, **.get_channel_sample_timestamps(channel_id, index_start, index_end)** rather than grabbing an existing data set, calculates timestamps from the **Tick** value from the InfoChannel structure of the Stream and the provided range. Also using the functions above the data internally is rearanged so no need to use any additional numpy functions here. \n",
    "\n",
    "The channel_IDs can be accquired by calling **.keys()** on the channel_infos of the respective stream."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_ids = channel_raw_data.recordings[0].analog_streams[1].channel_infos.keys()\n",
    "\n",
    "print(channel_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there are 8 channels within the stream. We take the key at index [0]. Sure this example looks a bit like overkill, but when iterating over multiple channels, this can be a way to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#channel_id = channel_raw_data.recordings[0].analog_streams[1].channel_infos.keys()[0]\n",
    "channel_id = list(channel_raw_data.recordings[0].analog_streams[1].channel_infos.keys())[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additional information can be accessed through **.info** on **.channel_infos[id]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_raw_data.recordings[0].analog_streams[1].channel_infos[0].info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Back to the plot. Grab the stream and the corresponding timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream = channel_raw_data.recordings[0].analog_streams[1]\n",
    "time = stream.get_channel_sample_timestamps(channel_id, 0, 10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we recalculte the values saved in the **time** variable to seconds with the included ureg function from the McsData module and extract the data of the desired channel with its ID and a range(0 to 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale time to seconds:\n",
    "scale_factor_for_second = Q_(1,time[1]).to(ureg.s).magnitude\n",
    "time_in_sec = time[0] * scale_factor_for_second\n",
    "\n",
    "signal = stream.get_channel_in_range(channel_id, 0, 10000)\n",
    "print(\"Signal: \",signal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To plot the spectogram of the data we also need to get the sampling frequency. For more information about metainformation of streams and data see the chapter <a href='#I2'>Info</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_frequency = stream.channel_infos[channel_id].sampling_frequency.magnitude "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then plot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "\n",
    "# Plot time domain\n",
    "axtp = plt.subplot(211)\n",
    "plt.plot(time_in_sec, signal[0])\n",
    "plt.xlabel('Time (%s)' % ureg.s)\n",
    "plt.ylabel('Voltage (%s)' % signal[1])\n",
    "plt.title('Sampled signal (%s)' % stream.label)\n",
    "\n",
    "# Plot frequency domain\n",
    "plt.subplot(212)\n",
    "plt.specgram(signal[0], NFFT=512, noverlap = 128, Fs = sampling_frequency, cmap = plt.cm.gist_heat, scale_by_freq = False)\n",
    "plt.xlabel('Time (%s)' % ureg.s)\n",
    "plt.ylabel('Frequency (Hz)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Compare multiple streams:\n",
    "\n",
    "To compare multiple streams they can also be plotted in one figure. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.output_notebook()\n",
    "\n",
    "# Assigning data\n",
    "stream1 = channel_raw_data.recordings[0].analog_streams[0]\n",
    "stream2 = channel_raw_data.recordings[0].analog_streams[1]\n",
    "channel_id = list(channel_raw_data.recordings[0].analog_streams[1].channel_infos.keys())[0]\n",
    "\n",
    "# Defining range\n",
    "time1 = stream1.get_channel_sample_timestamps(channel_id,0,3000)\n",
    "signal1 = stream1.get_channel_in_range(channel_id,0,3000)\n",
    "time2 = stream2.get_channel_sample_timestamps(channel_id,0,3000)\n",
    "signal2 = stream2.get_channel_in_range(channel_id,0,3000)\n",
    "\n",
    "# Bokeh-Plot\n",
    "bfig = bokeh.plotting.figure(plot_width=900, plot_height=400, title='Sampled signal overlay \\'%s\\' and \\'%s\\'' % (stream1.label, stream2.label))\n",
    "bfig.multi_line(\n",
    "    xs = [time1[0], time2[0]],\n",
    "    ys = [signal1[0], signal2[0]],\n",
    "    line_color = Spectral11[0:2],\n",
    "    alpha = 0.8\n",
    ")\n",
    "bfig.xaxis.axis_label = 'Time (%s)' % time1[1]\n",
    "bfig.yaxis.axis_label = 'Voltage (%s)' % signal1[1]\n",
    "bfig.ygrid.minor_grid_line_color = 'navy'\n",
    "bfig.ygrid.minor_grid_line_alpha = 0.1\n",
    "bokeh.plotting.show(bfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Heatmap of activity:\n",
    "\n",
    "Heatmaps are another way of displaying raw data like it's stored in AnalogStream_1. \n",
    "\n",
    "In this example all data from all channels are accessed by calling **.channel_data[:, 0:10000]**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = channel_raw_data.recordings[0].analog_streams[1].channel_data[:, 0:10000]\n",
    "aspect_ratio = 1000\n",
    "\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.set_cmap(\"jet\")\n",
    "plt.imshow(data, interpolation='nearest', aspect=aspect_ratio)\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Channel Number')\n",
    "plt.title('Heatmap of sampled wireless Signal')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <a href='#Top'>Back to index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FrameStream<a id='FS'></a>\n",
    "\n",
    "FrameStreams are a representation of the signals recorded by the chip of a CMOS-MEA system. \n",
    "\n",
    "The following examples demonstrate how to access all or just some of the data in respect to sensor position on the CMOS chip or timeframe of interest.\n",
    "\n",
    "We start of by setting the raw_data to an HDF5 file containing some FrameStream data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_raw_data = McsPy.McsData.RawData('.\\\\TestData\\\\Retina.h5')\n",
    "\n",
    "print(frame_raw_data.recordings[0].frame_streams[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we have one Stream with data included in our FrameStream and inside of that we have one FrameDataEntity which holds Data:\n",
    "\n",
    "    'Stream_0'\n",
    "    ->'FrameDataEntity_0'\n",
    "    \n",
    "For FrameStreams the ID instead of the index has to be taken when accessing the data of an entity. Just like in the example for AnalofStreams we can look at the IDs by calling **.keys()** on all entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_raw_data.recordings[0].frame_streams[0].frame_entity.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With **info.info** additional info can be accessed of the desired entity (frame_entity[1])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].info.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keys of the dictionary can be used to acces the values like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].info.info['Unit'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course the values aren't in Volt but the unit has to be adjusted with the 'Exponent'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].info.info['Exponent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code shows how the data and specific parts of it can be accessed by using **.data** and handing over a range of rows, columns, and frames.\n",
    "\n",
    "All rows and all columns of the first frame are: \n",
    "    \n",
    "    .data[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_data = frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].data\n",
    "\n",
    "first_frame = frame_data[:,:,0]\n",
    "\n",
    "sensor_calc = str(len(first_frame))+\" * \"+str(len(first_frame[0]))+\" = \"+str(len(first_frame)*len(first_frame[0]))\n",
    "\n",
    "print(frame_data)\n",
    "print()\n",
    "print(\"Each \\\"frame\\\" contains: \",sensor_calc,\" data points.\")\n",
    "print(\"Each point represents the value of one sensor of the CMOS-chip at a given timepoint.\")\n",
    "print(\"This FrameStream consists of 20000 frames.\")\n",
    "print()\n",
    "print(\"Array of the data contained in the first frame of the stream.\\n\",first_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot of a single frame (the first 65\\*65 frame, index 0) could look like this:\n",
    "\n",
    "Additionally to the data we need some conversion factors to adjust the values for each sensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_fact = np.array(frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].info.conversion_factors)\n",
    "\n",
    "print(conv_fact)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thanks to numpy's internals it is able to multiply two arrays of the same dimension like R would."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_data = np.array(frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].data[:,:,0])*conv_fact\n",
    "plt.set_cmap(\"Greys\") # change colors used by plot\n",
    "plt.imshow(f_data, interpolation='none',vmin=-350000, vmax=350000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of subplotted frames with defined frame interval:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2, ax3, ax4, ax5), ( ax6, ax7, ax8, ax9, ax10)) = plt.subplots(2, 5, sharex='col', sharey='row')\n",
    "fig.set_size_inches(18,6)\n",
    "ax_list = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10]\n",
    "\n",
    "for i in range(10,20):\n",
    "    current_frame = np.transpose(frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].data[:,:,i*1])*conv_fact\n",
    "    ax_list[i-10].imshow(current_frame, interpolation='none', vmin=-350000, vmax=350000)\n",
    "    ax_list[i-10].set_axis_off()\n",
    "    ax_list[i-10].set_title(\"Frame: \"+str(i*1))\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example of interactive plot of a FrameStream within a certain timeframe:\n",
    "\n",
    "With the slider the Timepoint that gets plotted can be defined. This value is handed over to the **make_plot** function. The interactive ipywidgets slider only works with jupyter notebooks but simmilar functionalities can be created with  matplotlib.widgets or by using graphical modules for python like Tkinter in regular python scripts/apps.\n",
    "\n",
    "Plot may \"flicker\", known ipywidgets.interact problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, HTML\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "plt.set_cmap(\"Greys\")  # change colors used by plot\n",
    "\n",
    "def make_plot(Frame=0):\n",
    "    \n",
    "    ffig = plt.figure(figsize=(8,8))\n",
    "    ax = plt.gca()\n",
    "    ax.set_title(\"Frame: \"+str(Frame))\n",
    "    current_frame = np.transpose(frame_data[:,:,Frame])*conv_fact\n",
    "    plt.imshow(current_frame, interpolation='none', vmin=-350000, vmax=350000)\n",
    "    plt.colorbar()\n",
    "    #plt.axis('off')\n",
    "    return HTML()  # said to slightly reduces flickering\n",
    "    \n",
    "   \n",
    "plt.show()\n",
    "       \n",
    "interact(make_plot, Frame=(0, 19999, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Viewing the data from a single/multiple sensor/s is also possible.\n",
    "\n",
    "The information needed to specify an area on the CMOS chip are the x/y-coordinates of the desired sensors and the indices of the frames which will be viewed. \n",
    "\n",
    "In this case **x-cords = 40 to 64** and **y_coords = 10 to 34** which get defined when defining the range_data variable, \n",
    "\n",
    "    range_data = frame_data[30:40,5:15,:]\n",
    "\n",
    "and with timestamp indices **0 to 54** which is defined interactively by the slider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,10))\n",
    "\n",
    "range_data = frame_data[40:64,10:34,:]\n",
    "\n",
    "def make_plot(Frame=0):\n",
    "    fig = plt.figure(figsize=(5,5))\n",
    "    current_frame = np.array(range_data[:,:,Frame])*conv_fact[40:64,10:34]\n",
    "    plt.imshow(current_frame, interpolation='none', vmin=-350000, vmax=350000)\n",
    "    ax = plt.gca()\n",
    "    plt.axis('off')  # don't display plot axis\n",
    "    ax.set_title(\"Frame: \"+str(Frame))\n",
    "    return HTML()  # slightly reduces flickering\n",
    "\n",
    "plt.show()\n",
    "        \n",
    "interact(make_plot, Frame=(0, 54, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of accessing the data of a single sensor is by using the .get_sensor_signal() function of the frame_entity. \n",
    "\n",
    "To do so, one has to provide the x/y-coordinates of the sensor that will get analyzed, aswell as the range of indices that will be viewed as arguments to the **.get_sensor_signal(sensor_x, sensor_y, idx_start, edx_end)** function.\n",
    "\n",
    "Additionally to guaranty a correct plot according to the time the data was gathered, the timestamp has to be added by calling **.get_frame_timestamps()** with the arguments **idx_start, idx_end** with the same values as the above call for the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single sensor:\n",
    "sensor_data = frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].get_sensor_signal(42,7,0,550)\n",
    "sensor_timestamps = frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].get_frame_timestamps(0,550)\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "plt.plot(sensor_timestamps[0], sensor_data[0], label=\"Single sensor\")\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel('Time in ms')\n",
    "plt.ylabel('Voltage in (%s)' % sensor_data[1])\n",
    "plt.title('Single sensor data')\n",
    "plt.show()\n",
    "\n",
    "# Multiple single sensors:\n",
    "sensor_data1 = (frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].get_sensor_signal(40,20,0,550),\"Data1\")\n",
    "sensor_data2 = (frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].get_sensor_signal(50,20,0,550),\"Data2\")\n",
    "sensor_data3 = (frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].get_sensor_signal(60,20,0,550),\"Data3\")\n",
    "\n",
    "sensor_list = [sensor_data1 ,sensor_data2, sensor_data3]\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "for sensor in range(3):\n",
    "    plt.plot(sensor_timestamps[0], sensor_list[sensor][0][0],label = sensor_list[sensor][1])\n",
    "\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "plt.xlabel('Time in ms')\n",
    "plt.ylabel('Voltage in (%s)' % sensor_data1[0][1])\n",
    "plt.title('Multiple sensor data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots can also be designed to be interactive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single sensor:\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "\n",
    "def single_plot(Frame=0):\n",
    "    fig = plt.figure(figsize=(15,5))\n",
    "    sensor_data = frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].get_sensor_signal(50,20,Frame,Frame+450)\n",
    "    \n",
    "    plt.plot(sensor_data[0], label=\"Single sensor\")\n",
    "    plt.ylim([-0.00023,0.0003])\n",
    "    plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    plt.xlabel('Timewindow')\n",
    "    plt.ylabel('Voltage in (%s)' % sensor_data[1])\n",
    "    plt.title('Single sensor data, Frame: '+str(Frame))\n",
    "    return HTML()  # slightly reduces flickering\n",
    "\n",
    "plt.show()\n",
    "\n",
    "interact(single_plot, Frame=(0, 550, 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you happen to have one of our CMOS-MEA systems, feel free to check out our example client written in Python for the CMOS-MEA-Control software, to visualize your experiments in realtime from any PC in your network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Top'>Back to index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EventStream<a id='ES'></a>\n",
    "\n",
    "EventStreams can be a wide array of events predefined by the user and stored in this stream. From the beginning/end or the duration of a treatment to periodically recurring stimuli this can be everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_raw_data_file_path = \".\\\\TestData\\\\2014-07-09T10-17-35W8 Standard all 500 Hz.h5\"\n",
    "\n",
    "event_raw_data = McsPy.McsData.RawData(test_raw_data_file_path)\n",
    "\n",
    "event_entity = event_raw_data.recordings[0].event_streams[0].event_entity[0]\n",
    "\n",
    "print(\"EventEntity_0 contains: %s events\" % event_entity.count)\n",
    "all_events = event_entity.get_events()\n",
    "print()\n",
    "print(\"All events: \",all_events)\n",
    "print()\n",
    "print(all_events[0][0])\n",
    "print()\n",
    "all_event_timestamps = event_entity.get_event_timestamps()\n",
    "print(all_event_timestamps[0])\n",
    "print()\n",
    "all_event_durations = event_entity.get_event_durations()\n",
    "print(all_event_durations[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More info with **.info.info**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_entity.info.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization of this information is best combined with other data-types to highlight the occurance of events.\n",
    "\n",
    "Depending on the data these plots don't necessarily overlap.\n",
    "\n",
    "First we get the data we want to plot. In this case the data from the AnalogStreams and the data from the TimestampStream is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream1 = event_raw_data.recordings[0].analog_streams[0]\n",
    "stream2 = event_raw_data.recordings[0].analog_streams[1]\n",
    "channel_id = list(event_raw_data.recordings[0].analog_streams[1].channel_infos.keys())[0]\n",
    "timestamps = event_raw_data.recordings[0].timestamp_streams[0].timestamp_entity[0].get_timestamps()[0]\n",
    "\n",
    "time1 = stream1.get_channel_sample_timestamps(channel_id,0,3000)\n",
    "signal1 = stream1.get_channel_in_range(channel_id,0,3000)\n",
    "time2 = stream2.get_channel_sample_timestamps(channel_id,0,3000)\n",
    "signal2 = stream2.get_channel_in_range(channel_id,0,3000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we plot the AnalogStreams according to the Timestamps.\n",
    "\n",
    "Then we add some vertical lines representing the Events.\n",
    "\n",
    "Finally we define some plot properties and we are done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,12))\n",
    "plt.plot(time1[0], signal1[0])\n",
    "plt.plot(time2[0], signal2[0])\n",
    "max_time = max(time1[0][-1],time2[0][-1])\n",
    "\n",
    "for event in all_events[0][0]:\n",
    "    if event < max_time:\n",
    "        plt.axvline(event, color='r') \n",
    "        \n",
    "plt.xlabel('Time (%s)' % time1[1])\n",
    "plt.ylabel('Voltage (%s)' % signal1[1])\n",
    "plt.title('Sampled signal overlay \\'%s\\' and \\'%s\\'' % (stream1.label, stream2.label))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Top'>Back to index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SegmentStream<a id='SS'></a>\n",
    "\n",
    "SegmentStreams are further split up into two subtypes:\n",
    "\n",
    "- Cutouts: As the name already implies these bits of data are predefined cutouts of a certain dimension from the signal received by the electrodes.\n",
    "- Averages: Are averages of those cutouts, for all cutouts at certain timepoints\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "    python DataStreamInfo.py --f AnalogSegmentTimestamp.h5\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtype: Cutouts<a id='SC'></a>\n",
    "\n",
    "    Date                 Program    Version\n",
    "    -------------------  ---------  ---------\n",
    "    2014-07-25 11:30:56  MC_Rack    4.5.12.0\n",
    "\n",
    "    Type       Stream    # ch\n",
    "    ---------  --------  ------\n",
    "    Analog               60\n",
    "    Segment\n",
    "    TimeStamp\n",
    "\n",
    "For SegmentStreams you can extract a single entity by addressing its index.\n",
    "\n",
    "So the first SegmentEntity at index 0 would be:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_raw_data = McsPy.McsData.RawData('.\\\\TestData\\\\AnalogSegmentTimestamp.h5')\n",
    "\n",
    "first_segment_entity = segment_raw_data.recordings[0].segment_streams[0].segment_entity[0]\n",
    "\n",
    "print()\n",
    "print(\"Segment entity 0 contains: %s segments\" % first_segment_entity.segment_sample_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again a full list of of entities to iterate over can be generated with **.keys**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_stream_keys = segment_raw_data.recordings[0].segment_streams[0].segment_entity.keys()\n",
    "\n",
    "print(segment_stream_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data of one of these entities can either be accessed by **.data**, but several steps have to be applied for the data to make sense when plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = segment_raw_data.recordings[0].segment_streams[0].segment_entity[0].data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.reshape(data, -1, 'F')\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = segment_raw_data.recordings[0].segment_streams[0].segment_entity[0].info.source_channel_of_segment[0].adc_step.magnitude\n",
    "print(scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data * scale\n",
    "bokeh.io.output_notebook()  # see comment for bokeh module in \"Requirements\" section\n",
    "bfig = bokeh.plotting.figure(plot_width=900, plot_height=400)\n",
    "bfig.line(list(range(len(data))),data, alpha=0.8)\n",
    "bfig.ygrid.minor_grid_line_color = 'navy'\n",
    "bfig.ygrid.minor_grid_line_alpha = 0.1\n",
    "bokeh.plotting.show(bfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**.data_ts** yields the corresponding timestamps of the segment entity but to be used together similar reformating has to be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal = first_segment_entity.get_segment_in_range(segment_id = 0, flat = True)\n",
    "\n",
    "print(signal[0])\n",
    "print(signal[1])\n",
    "\n",
    "bokeh.io.output_notebook()  # see comment for bokeh module in \"Requirements\" section\n",
    "bfig = bokeh.plotting.figure(plot_width=900, plot_height=400)\n",
    "bfig.line(list(range(len(data))),data, alpha=0.8)\n",
    "bfig.xaxis.axis_label = 'Sample Index'\n",
    "bfig.yaxis.axis_label = 'Voltage (%s)' % signal1[1]\n",
    "bfig.ygrid.minor_grid_line_color = 'navy'\n",
    "bfig.ygrid.minor_grid_line_alpha = 0.1\n",
    "bokeh.plotting.show(bfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the above steps are rather complicated. Therefor custom functions have been already implemented in **McsPy** to make your life easier: \n",
    "\n",
    "**get_segment_in_range()** \n",
    "\n",
    "and\n",
    "\n",
    "**get_segment_sample_timestamps()**\n",
    "\n",
    "\n",
    "With this built-in function one can select ranges of these segments included in the SegmentEntities. \n",
    "\n",
    "If you want to plot the included data to quickly visualize it you need two things:\n",
    "\n",
    "1. the signal itself\n",
    "2. the corresponding timestamp\n",
    "\n",
    "For this we can use **get_segment_in_range()** and **get_segment_sample_timestamps()**. Arguments that can be passed are:\n",
    "\n",
    "- **segment_id**: Id of the SegmentData within the Entity that will be analyzed\n",
    "- **flat**: False will leave data dimensions unchanged, True will convert data into a one-dimensional vector of the sequentially ordered segments\n",
    "- **idx_start**: Index of the first segment that should be returned. If left unspecified will be first possible index.\n",
    "- **idx_end**: Index of the last segment that should be returned If left unspecified will be last possible index.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameter **flat** needs to be set to True, so the data is **flattened** into a one-dimensional array and matplotlibs plot function can handle it.\n",
    "\n",
    "Overlaying data from all segments might look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.output_notebook()\n",
    "\n",
    "signal_ts = first_segment_entity.get_segment_sample_timestamps(segment_id = 0, flat = True)\n",
    "\n",
    "factor = ureg.convert(1, str(signal_ts[1]), \"second\")\n",
    "signal_ts_second = signal_ts[0] * factor\n",
    "\n",
    "# Bokeh-Plot\n",
    "bfig = bokeh.plotting.figure(plot_width=900, plot_height=400, title='Sampled Signal Segments')\n",
    "bfig.multi_line(\n",
    "    xs = [signal_ts_second] * 60,\n",
    "    ys = [segment_raw_data.recordings[0].segment_streams[0].segment_entity[i].get_segment_in_range(segment_id = 0, flat = True)[0] for i in segment_raw_data.recordings[0].segment_streams[0].segment_entity.keys()],\n",
    "    alpha = 0.5\n",
    ")\n",
    "#bfig.line(signal_ts_second, segment_raw_data.recordings[0].segment_streams[0].segment_entity[i].get_segment_in_range(segment_id = 0, flat = True)[0], alpha=0.8)\n",
    "bfig.xaxis.axis_label = 'Time (%s)' % ureg.s\n",
    "bfig.yaxis.axis_label = 'Voltage (%s)' % signal1[1]\n",
    "bfig.ygrid.minor_grid_line_color = 'navy'\n",
    "bfig.ygrid.minor_grid_line_alpha = 0.1\n",
    "bokeh.plotting.show(bfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subtype: Averages <a id='SA'></a>\n",
    "\n",
    "Averages are a convenient built-in way to get precalculated values for mean and standard deviation of a collection of predefineable sensors/timeframes.\n",
    "\n",
    "Calling DataStreamInfo.py on AverageEvent.h5 reveals its content\n",
    "\n",
    "    Date                 Program           Version\n",
    "    -------------------  ----------------  ---------\n",
    "    2015-04-02 16:04:26  Multiwell-Screen  1.2.1.0\n",
    "\n",
    "    Type     Stream                              # ch\n",
    "    -------  ----------------------------------  ------\n",
    "    Event    Experiment State Changes_00 Atrium\n",
    "    Event    Applied Dilution Series_00 Atrium\n",
    "    Segment  Averages_00 Atrium\n",
    "    \n",
    "The file has three Streams: Two **EventStreams** which, in this case, hold information about state changes of the experiment aswell as applied dilutions and one **AverageStream**, in this case holding data from an experiment mith cardiac muscel cells. \n",
    "\n",
    "Data access looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_raw_data = McsPy.McsData.RawData(\".\\\\TestData\\\\AverageEvent.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_data = average_raw_data.recordings[0].segment_streams[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the the entities are unconsecutavely numbered by id and not consecutively by index. To be able to iterate over all entities of the stream we have to get a list of indices.\n",
    "\n",
    "By looking at how McsData.py accesses the HDF5 file we know that upon initialization of the stream a dictionary is created with IDs and values. With pythons **.keys()** we can create a list of all entity IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = average_data.segment_entity.keys()\n",
    "\n",
    "id_list = sorted(id_list)\n",
    "\n",
    "print(id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just like addressing FrameStreamEntities instead of an index we need to provide the ID of the entity, in this case one of the electrodes within a single well, we want to analyze. Let's pick 31 from the index_list we just generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_data_31 = average_raw_data.recordings[0].segment_streams[0].segment_entity[31].data\n",
    "\n",
    "print(average_data_31)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When looking at the data with HDFView 2.11 we see how the data is aranged within the file. It has 2 rows, row 0 holds the mean values and row 2 holds the values for standard deviation, 5100 columns representing timpoints of measurement, and 9 sheets, in this case representing different treatments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So to get the mean values(index 0), all of them (index 0 to intex 5100) of the first treatment(index 0) and plot these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.plot(average_data_31[0,0:5100,0])\n",
    "\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting all 9 treatments/sheets could look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bokeh.io.output_notebook()  # see comment for bokeh module in \"Requirements\" section\n",
    "bfig = bokeh.plotting.figure(plot_width=900, plot_height=400, title='All Treatments')\n",
    "for sheet in range(9):\n",
    "    bfig.line(# plot line with it's own color\n",
    "        list(range(average_data_31.shape[1])), \n",
    "        average_data_31[0,:5100,sheet],\n",
    "        color = Spectral11[sheet], \n",
    "        legend = \"Data_\"+str(sheet),\n",
    "        line_width = 2,\n",
    "        alpha = 0.8\n",
    "    )\n",
    "bfig.legend.location = \"top_right\"\n",
    "bfig.legend.click_policy =\"hide\"\n",
    "bfig.xaxis.axis_label = 'Sample Index'\n",
    "bfig.yaxis.axis_label = 'ADC Value'\n",
    "bfig.ygrid.minor_grid_line_color = 'navy'\n",
    "bfig.ygrid.minor_grid_line_alpha = 0.1\n",
    "bokeh.plotting.show(bfig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the data from all sensors might look like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index_list: see above\n",
    "\n",
    "fig, ((ax1, ax2, ax3, ax4), (ax5, ax6, ax7, ax8), (ax9, ax10, ax11, ax12)) = plt.subplots(3, 4, sharex='col', sharey='row')\n",
    "fig.set_size_inches(6,6)\n",
    "ax_list = [ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8, ax9, ax10, ax11, ax12]\n",
    "\n",
    "fig.set_size_inches(15,10)\n",
    "\n",
    "for i in range(len(ax_list)-1):\n",
    "    x = average_raw_data.recordings[0].segment_streams[0].segment_entity[id_list[i]].data.shape[2]\n",
    "    color = iter(plt.cm.jet(np.linspace(0,1,x))) # generate as many distinct colors as there are lines that will be plotted\n",
    "                                                 # you can replace jet with cool or winter or any other matplotlib colormap\n",
    "    for k in range(x):\n",
    "            current_average = average_raw_data.recordings[0].segment_streams[0].segment_entity[id_list[i]].data[0,:5100,k]\n",
    "            c = next(color)  # select color from custom colormap\n",
    "            ax_list[i].plot(current_average, c = c)\n",
    "            ax_list[i].set_title(\"Index: \"+str(id_list[i]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Top'>Back to index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TimestampStream <a id='TS'></a>\n",
    "\n",
    "As you might have noticed some of the plots already accessed the according timestamps. Depending on your settings these may stand for beginnings and/or ends of certain events.\n",
    "\n",
    "Accessing the data within a TimestampStream is achieved by calling the **.get_timestamps()** function of a **.timestamp_entity** within **.timestamp_streams**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps_raw_data = McsPy.McsData.RawData('.\\\\TestData\\\\2014-07-09T10-17-35W8 Standard all 500 Hz.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamps = timestamps_raw_data.recordings[0].timestamp_streams[0].timestamp_entity[0].get_timestamps()\n",
    "print()\n",
    "\n",
    "# Array of everything concerning the timestamps of the entity\n",
    "print(timestamps)\n",
    "print()\n",
    "\n",
    "# Just the timestamps\n",
    "print(\"Timestamps: \", timestamps[0][0])\n",
    "print()\n",
    "\n",
    "# The unit the values are in\n",
    "print(\"Unit: \", timestamps[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how these data might be used for visualization purposses we can plot these together with some data from the AnalogStream.\n",
    "\n",
    "We will use the built-in functions **.get_channel_in_range()** and **.get_channel_sample_timestamps()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stream1 = event_raw_data.recordings[0].analog_streams[0]\n",
    "stream2 = event_raw_data.recordings[0].analog_streams[1]\n",
    "channel_id = list(event_raw_data.recordings[0].analog_streams[1].channel_infos.keys())[0]\n",
    "timestamps = event_raw_data.recordings[0].timestamp_streams[0].timestamp_entity[0].get_timestamps()[0]\n",
    "print(timestamps)\n",
    "\n",
    "time1 = stream1.get_channel_sample_timestamps(channel_id,0,3000)\n",
    "print(\"Time1\",time1)\n",
    "signal1 = stream1.get_channel_in_range(channel_id,0,3000)\n",
    "time2 = stream2.get_channel_sample_timestamps(channel_id,0,3000)\n",
    "print(\"Time2\",time2)\n",
    "signal2 = stream2.get_channel_in_range(channel_id,0,3000)\n",
    "\n",
    "plt.figure(figsize=(16,6))\n",
    "plt.plot(time1[0], signal1[0])\n",
    "plt.plot(time2[0], signal2[0])\n",
    "max_time = max(time1[0][-1],time2[0][-1])\n",
    "\n",
    "[plt.axvline(timestamp, color='r') for timestamp in timestamps[0,:] if timestamp < max_time]\n",
    "\n",
    "plt.xlabel('Time (%s)' % time1[1])\n",
    "plt.ylabel('Voltage (%s)' % signal1[1])\n",
    "plt.title('Sampled signal overlay \\'%s\\' and \\'%s\\'' % (stream1.label, stream2.label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Top'>Back to index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Info <a id='I2'></a>\n",
    "\n",
    "As depicted in the graphical representation of the class structure of the McsData.py module, every stream has an info file associated with it which holds additional information about the data included in the entities of those streams. This additional information can be used for simpler tasks like labeling axes with units stored in the info file or to sort streams according to parameters which are deposited in this kind of file.\n",
    "\n",
    "Below you find a collection of commands to access the data of the info files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing AnalogStream Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_raw_data.recordings[0].analog_streams[0].channel_infos[0].info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_raw_data.recordings[0].analog_streams[0].channel_infos[0].info['ConversionFactor'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see the data is aranged in a dictionary, so we can geta all the keys with **.keys()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "info_keys = channel_raw_data.recordings[0].analog_streams[0].channel_infos[0].info.keys()\n",
    "\n",
    "print(info_keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can use this list to iterate over it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in info_keys:\n",
    "    print(\"Key:\",key,\", Value:\",channel_raw_data.recordings[0].analog_streams[0].channel_infos[0].info[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For AnalogStreams there are some built-in functions you can call on **.channel_infos[index]**. \n",
    "\n",
    "- **.adc_step**\n",
    "- **.channel_id**\n",
    "- **.row_index**\n",
    "- **.version**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If sampled data is enclosed in the AnalogStream\n",
    "\n",
    "- **.sampling_frequency**\n",
    "- **.sampling_tick**\n",
    "\n",
    "can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(channel_raw_data.recordings[0].analog_streams[0].channel_infos[0].sampling_frequency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Entities **.info.info** reveales additional info."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing FrameStream Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].info.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].info.info['RawDataType'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition there are:\n",
    "\n",
    "- **.info.frame_id**\n",
    "- **.info.sensor_spacing**\n",
    "- **.info.adc_basic_step**\n",
    "- **.info.adc_step_for_sensor(x, y)** x,y are the coordinates of the sensor. Sensor 1 has (0, 0) sensor 4225 has (65, 65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(frame_raw_data.recordings[0].frame_streams[0].frame_entity[1].info.adc_step_for_sensor(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing EventStream Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_raw_data.recordings[0].event_streams[0].event_entity[0].info.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(event_raw_data.recordings[0].event_streams[0].event_entity[0].info.info['SourceChannelIDs'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For EventStreams additionly there are \n",
    "\n",
    "- **.info.id**\n",
    "- **.info.raw_data_bytes**\n",
    "- **.info.source_channel_ids**\n",
    "- **.info.source_channel_labels**\n",
    "- **.info.version** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing SegmentStream Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_raw_data.recordings[0].segment_streams[0].segment_entity[31].info.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_raw_data.recordings[0].segment_streams[0].segment_entity[31].info.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_raw_data.recordings[0].segment_streams[0].segment_entity[31].info.info['Label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Segments there also are:\n",
    "\n",
    "- **.info.count**\n",
    "- **.info.id**\n",
    "- **.info.post_interval**\n",
    "- **.info.pre_interval**\n",
    "- **.info.type**\n",
    "- **.info.version**\n",
    "\n",
    "This holds true for cutout and average data alike.\n",
    "\n",
    "For entities with averages you can use\n",
    "\n",
    "- **.number_of_averages**\n",
    "- **.sample_length**\n",
    "- **.time_ranges**\n",
    "- **.time_range(index)**\n",
    "- **.average_counts**\n",
    "- **.average_count(index)**\n",
    "- **.segment_sample_count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(average_raw_data.recordings[0].segment_streams[0].segment_entity[31].number_of_averages)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing TimestampStream Info:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(timestamps_raw_data.recordings[0].timestamp_streams[0].timestamp_entity[0].info.info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but not least Timestamps have: \n",
    "\n",
    "- **.info.data_type**\n",
    "- **.info.exponent**\n",
    "- **.info.id**\n",
    "- **.info.measuring_unit**\n",
    "- **.info.source_channel_ids**\n",
    "- **.info.source_channel_labels**\n",
    "- **.info.unit**\n",
    "- **.info.version**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Top'>Back to index</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing your Data with McsCMOS<a id='Accessing your Data with McsCMOS'></a> (under construction)\n",
    "\n",
    "\n",
    "The classes included in the McsCMOS module were designed to allow easy access of HDF5 files containing CMOS data.\n",
    "\n",
    "Namely there are 3 classe:\n",
    " - CMOSData <a id='CMOSData'></a>\n",
    " - CMOSConvProxy\n",
    " - CMOSSpike\n",
    " \n",
    "Basically it's another way to obtain FrameStream data but with added functionality.\n",
    "\n",
    "This is achieved through internel calls to predefined regions of the HDF5 file, as the CMOS systems only yield certain types of data.\n",
    "\n",
    "Where you had to call:\n",
    "\n",
    "    frame_data = McsPy.McsData.RawData.recordings[0].frame_streams[0].frame_entity[1].data(file_path)\n",
    "    \n",
    "most of this is internalized and the reduced call looks like:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata_path = \".\\\\TestData\\\\CMOSTestRec.h5\"\n",
    "\n",
    "CMOS_data = McsPy.McsCMOS.CMOSData('.\\\\TestData\\\\Retina.h5')\n",
    "\n",
    "print(CMOS_data.raw_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Data can be handled as demonstrated in the <a href='#FrameStream'>FrameStream</a> example before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href='#Top'>Back to index</a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
